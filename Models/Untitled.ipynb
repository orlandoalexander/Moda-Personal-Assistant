{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41815112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:48:51.949146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 12:48:52.066968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:48:52.066984: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-07 12:48:52.092459: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-07 12:48:52.784737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:48:52.784900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:48:52.784911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.layers import Input\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fbc5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b50dfe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'img', 'category', 'section', 'floral', 'graphic',\n",
       "       'striped', 'embroidered', 'pleated', 'solid', 'lattice', 'long_sleeve',\n",
       "       'short_sleeve', 'sleeveless', 'maxi_length', 'mini_length', 'no_dress',\n",
       "       'crew_neckline', 'v_neckline', 'square_neckline', 'no_neckline',\n",
       "       'denim', 'chiffon', 'cotton', 'leather', 'faux', 'knit', 'tight',\n",
       "       'loose', 'conventional', 'x_1', 'y_1', 'x_2', 'y_2', 'v1', 'x1', 'y1',\n",
       "       'v2', 'x2', 'y2', 'v3', 'x3', 'y3', 'v4', 'x4', 'y4', 'v5', 'x5', 'y5',\n",
       "       'v6', 'x6', 'y6', 'v7', 'x7', 'y7', 'v8', 'x8', 'y8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8f02304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac51dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9d456ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For now this class takes in data_full.csv and the path to the images\n",
    "\n",
    "# In the future it will receive data directly from preprocessing\n",
    "\n",
    "# Data will be split but here I add a split_data function\n",
    "\n",
    "# Works with data_full passed for data\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, attribute,\n",
    "                data: pd.DataFrame,\n",
    "                img_shape: tuple):\n",
    "\n",
    "        # Columns for each attribute are:\n",
    "        self.attributes = {\n",
    "                    'design': [np.r_[0,3:10], 7],     # idx 0 are data_full columns\n",
    "                    'sleeves': [np.r_[0,10:13], 3],   # idx 1 are num attributes\n",
    "                    'length': [np.r_[0,13:15], 2],\n",
    "                    'neckline':[np.r_[0,16:20], 4],\n",
    "                    'fabric': [np.r_[0,20:26], 6],\n",
    "                    'fit': [np.r_[0,26:29], 3]\n",
    "                }\n",
    "        self.data = data.iloc[self.attributes[attribute][0]]  # only img and design columns\n",
    "        self.img_shape = img_shape\n",
    "        self.num_cats = self.attributes[attribute][1]\n",
    "        self.model = self.instatiate_inception()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_data()\n",
    "\n",
    "    def split_data(self):\n",
    "        # Split data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.data['img'], self.data.drop(columns='img'),\n",
    "            test_size=0.3, random_state=2)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def instatiate_inception(self):                     # Inception V3 model\n",
    "        input_layer = Input(shape=(299,299,3))          # Image size (299, 299) specific to Inception V3\n",
    "        inception = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
    "        for layer in inception.layers:\n",
    "            layer.trainable = False               # Freeze layers\n",
    "        model = Sequential(inception)\n",
    "        model.add(Flatten())\n",
    "        model.add(Den'se(500))                           # Let's play with these last layers\n",
    "        if self.num_cats == 2:\n",
    "            model.add(Dense(2, activation='sigmoid'))\n",
    "        else:\n",
    "            model.add(Dense(self.num_cats, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=[Precision(), Recall()])\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        history = self.model.fit(np.array(self.X_train), self.y_train,\n",
    "                batch_size=16,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss',\n",
    "                                        patience=5,\n",
    "                                        restore_best_weights=True)],\n",
    "                validation_split=0.2)\n",
    "        return history        # Do I need to return the model?\n",
    "\n",
    "    def test(self):\n",
    "        score = self.model.evaluate(np.array(self.X_test), self.y_test, verbose=1)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        return score\n",
    "\n",
    "    def predict(self):\n",
    "        y_pred = self.model.predict(np.array(self.X_test))\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ded16c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(attribute='design',\n",
    "              data = data,\n",
    "              img_shape=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c7c4141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 500)               65536500  \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 7)                 3507      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,342,791\n",
      "Trainable params: 65,540,007\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5519142b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'design': [array([0, 3, 4, 5, 6, 7, 8, 9]), 7],\n",
       " 'sleeves': [array([ 0, 10, 11, 12]), 3],\n",
       " 'length': [array([ 0, 13, 14]), 2],\n",
       " 'neckline': [array([ 0, 16, 17, 18, 19]), 4],\n",
       " 'fabric': [array([ 0, 20, 21, 22, 23, 24, 25]), 6],\n",
       " 'fit': [array([ 0, 26, 27, 28]), 3]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bd1f54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img</th>\n",
       "      <th>category</th>\n",
       "      <th>section</th>\n",
       "      <th>floral</th>\n",
       "      <th>graphic</th>\n",
       "      <th>striped</th>\n",
       "      <th>embroidered</th>\n",
       "      <th>pleated</th>\n",
       "      <th>solid</th>\n",
       "      <th>...</th>\n",
       "      <th>y5</th>\n",
       "      <th>v6</th>\n",
       "      <th>x6</th>\n",
       "      <th>y6</th>\n",
       "      <th>v7</th>\n",
       "      <th>x7</th>\n",
       "      <th>y7</th>\n",
       "      <th>v8</th>\n",
       "      <th>x8</th>\n",
       "      <th>y8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sweet_Crochet_Blouse/img_00000070.jpg</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>upper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mid-Rise_-_Acid_Wash_Skinny_Jeans/img_00000010...</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>lower</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Zippered_Single-Button_Blazer/img_00000078.jpg</td>\n",
       "      <td>Blazer</td>\n",
       "      <td>upper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Abstract_Chevron_Draped_Dress/img_00000013.jpg</td>\n",
       "      <td>Dress</td>\n",
       "      <td>full body</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Boho_Babe_Crochet_Top/img_00000047.jpg</td>\n",
       "      <td>Top</td>\n",
       "      <td>upper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Colorblock-Paneled_Tee/img_00000006.jpg</td>\n",
       "      <td>Tee</td>\n",
       "      <td>upper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Abstract_Floral_Print_Kimono/img_00000026.jpg</td>\n",
       "      <td>Kimono</td>\n",
       "      <td>full body</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Stripe_Trapeze_Dress/img_00000010.jpg</td>\n",
       "      <td>Dress</td>\n",
       "      <td>full body</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                img category  \\\n",
       "0           0              Sweet_Crochet_Blouse/img_00000070.jpg   Blouse   \n",
       "3           3  Mid-Rise_-_Acid_Wash_Skinny_Jeans/img_00000010...    Jeans   \n",
       "4           4     Zippered_Single-Button_Blazer/img_00000078.jpg   Blazer   \n",
       "5           5     Abstract_Chevron_Draped_Dress/img_00000013.jpg    Dress   \n",
       "6           6             Boho_Babe_Crochet_Top/img_00000047.jpg      Top   \n",
       "7           7            Colorblock-Paneled_Tee/img_00000006.jpg      Tee   \n",
       "8           8      Abstract_Floral_Print_Kimono/img_00000026.jpg   Kimono   \n",
       "9           9              Stripe_Trapeze_Dress/img_00000010.jpg    Dress   \n",
       "\n",
       "     section  floral  graphic  striped  embroidered  pleated  solid  ...  \\\n",
       "0      upper       0        0        0            1        0      0  ...   \n",
       "3      lower       0        0        0            0        0      1  ...   \n",
       "4      upper       0        0        0            0        0      1  ...   \n",
       "5  full body       1        0        0            0        0      0  ...   \n",
       "6      upper       0        0        0            0        0      1  ...   \n",
       "7      upper       0        0        0            0        0      1  ...   \n",
       "8  full body       1        0        0            0        0      0  ...   \n",
       "9  full body       0        0        1            0        0      0  ...   \n",
       "\n",
       "      y5   v6     x6     y6   v7    x7     y7   v8     x8     y8  \n",
       "0  273.0  0.0  212.0  267.0  0.0   0.0    0.0  0.0    0.0    0.0  \n",
       "3    0.0  0.0    0.0    0.0  0.0   0.0    0.0  0.0    0.0    0.0  \n",
       "4  281.0  0.0  186.0  280.0  0.0   0.0    0.0  0.0    0.0    0.0  \n",
       "5  165.0  0.0  109.0  162.0  0.0  41.0  282.0  0.0  127.0  278.0  \n",
       "6  234.0  0.0  132.0  232.0  0.0   0.0    0.0  0.0    0.0    0.0  \n",
       "7  258.0  1.0  135.0  247.0  0.0   0.0    0.0  0.0    0.0    0.0  \n",
       "8  189.0  0.0  145.0  185.0  1.0  56.0  234.0  1.0  142.0  251.0  \n",
       "9  166.0  0.0  153.0  163.0  0.0  70.0  286.0  0.0  165.0  290.0  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a6fd4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "000a47ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 54\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/taxifare-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/taxifare-env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "history = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041cae37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
