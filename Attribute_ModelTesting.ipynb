{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orlandoalexander/Moda-Personal-Assistant/blob/models/Attribute_ModelTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.layers import Input\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "c1TXSUxe5Q_J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HotamS6T5ONO",
        "outputId": "e53b81a5-e877-46b5-9041-109fbfcbe395"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade pip\n"
      ],
      "metadata": {
        "id": "yq8UFwXCvvCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da31e9ab-2c27-4f5d-e33c-8b4fd7758f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/orlandoalexander/Moda-Personal-Assistant.git@preproc_package\n"
      ],
      "metadata": {
        "id": "fF8likxwv70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91a06c82-cf48-4a3d-80bc-9b28b039b35d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/orlandoalexander/Moda-Personal-Assistant.git@preproc_package\n",
            "  Cloning https://github.com/orlandoalexander/Moda-Personal-Assistant.git (to revision preproc_package) to /tmp/pip-req-build-jrb2upwy\n",
            "  Running command git clone -q https://github.com/orlandoalexander/Moda-Personal-Assistant.git /tmp/pip-req-build-jrb2upwy\n",
            "  Running command git checkout -b preproc_package --track origin/preproc_package\n",
            "  Switched to a new branch 'preproc_package'\n",
            "  Branch 'preproc_package' set up to track remote branch 'preproc_package' from 'origin'.\n",
            "Collecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.7 MB 3.7 MB/s \n",
            "\u001b[?25hCollecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 72.7 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.5.2\n",
            "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn-pandas==1.8.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.8.0)\n",
            "Requirement already satisfied: absl-py==1.3.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.8.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.6.3)\n",
            "Requirement already satisfied: cachetools==5.2.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (5.2.0)\n",
            "Requirement already satisfied: certifi==2022.9.24 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.1.1)\n",
            "Collecting flatbuffers==22.12.6\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.4.0)\n",
            "Requirement already satisfied: google-auth==2.15.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.4.6)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio==1.51.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.51.1)\n",
            "Collecting h5py==3.7.0\n",
            "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 56.2 MB/s \n",
            "\u001b[?25hCollecting idna==3.4\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 64 kB/s \n",
            "\u001b[?25hCollecting importlib-metadata==5.1.0\n",
            "  Downloading importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.1.2)\n",
            "Requirement already satisfied: libclang==14.0.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (14.0.6)\n",
            "Requirement already satisfied: Markdown==3.4.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.4.1)\n",
            "Collecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.2.2)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.3.0)\n",
            "Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (21.3)\n",
            "Requirement already satisfied: protobuf==3.19.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.19.6)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.2.8)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2022.6)\n",
            "Collecting requests==2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (4.9)\n",
            "Collecting scikit-learn==1.1.3\n",
            "  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 116.2 MB/s \n",
            "\u001b[?25hCollecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tensorboard-data-server==0.6.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.8.1)\n",
            "Requirement already satisfied: termcolor==2.1.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.1.1)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions==4.4.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (4.4.0)\n",
            "Collecting urllib3==1.26.13\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 96.6 MB/s \n",
            "\u001b[?25hCollecting Werkzeug==2.2.2\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 97.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt==1.14.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.14.1)\n",
            "Requirement already satisfied: zipp==3.11.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.11.0)\n",
            "Collecting keras==2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 83.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard==2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 66.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 72.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse==1.6.3->preproc==0.0.0) (0.38.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->preproc==0.0.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->preproc==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->preproc==0.0.0) (7.1.2)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11->preproc==0.0.0) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->preproc==0.0.0) (0.28.0)\n",
            "Building wheels for collected packages: preproc\n",
            "  Building wheel for preproc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preproc: filename=preproc-0.0.0-py3-none-any.whl size=12852291 sha256=963ad6bb2dbe9e2c290ac1eeddbc8118dbb64ea805c330392d746a8925946d25\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qgfje14o/wheels/3a/d8/cf/a54e93734385125d287cb7e11625303456bc04eefd73764145\n",
            "Successfully built preproc\n",
            "Installing collected packages: urllib3, idna, six, requests, numpy, MarkupSafe, importlib-metadata, Werkzeug, scipy, tensorflow-estimator, tensorboard, scikit-learn, pandas, keras, h5py, fonttools, flatbuffers, tensorflow, matplotlib, preproc\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.13.0\n",
            "    Uninstalling importlib-metadata-4.13.0:\n",
            "      Successfully uninstalled importlib-metadata-4.13.0\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed MarkupSafe-2.1.1 Werkzeug-2.2.2 flatbuffers-22.12.6 fonttools-4.38.0 h5py-3.7.0 idna-3.4 importlib-metadata-5.1.0 keras-2.11.0 matplotlib-3.5.2 numpy-1.23.5 pandas-1.4.4 preproc-0.0.0 requests-2.28.1 scikit-learn-1.1.3 scipy-1.9.3 six-1.16.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 urllib3-1.26.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "h5py",
                  "keras",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "requests",
                  "six",
                  "sklearn",
                  "tensorboard",
                  "tensorflow",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip '/content/drive/MyDrive/attribute_img/img.zip''\n",
        "!unzip '/content/drive/MyDrive/Le Wagon/Moda-Personal-Assistant/Data/img.zip'"
      ],
      "metadata": {
        "id": "WTijLFXOh_g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from preproc.preprocess import AttributePreproc\n"
      ],
      "metadata": {
        "id": "QA8yjzxuwAgU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep = AttributePreproc('img', (224,224), 'sleeves', 0.2) "
      ],
      "metadata": {
        "id": "an3Vit6udBvo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test  = prep.run()"
      ],
      "metadata": {
        "id": "yTU4WRpWvvF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f025dfd8-aad3-4bea-dfb4-b5cf30e7d149"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmenting attribute 'long_sleeve'...\n",
            "Augmenting attribute 'short_sleeve'...\n",
            "Augmenting attribute 'sleeveless'...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Lambda\n",
        "from keras import Sequential\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.applications import InceptionV3\n",
        "from keras.applications import inception_v3\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications import mobilenet_v2\n",
        "from keras.applications import EfficientNetB0\n",
        "from keras.applications import efficientnet\n",
        "from keras.applications import mobilenet\n",
        "from keras.applications import resnet\n",
        "from keras.applications import inception_v3\n",
        "\n",
        "# attribute should be one of the following strings:\n",
        "# 'design', 'sleeves', 'length', 'neckline', 'fabric', 'fit'\n",
        "\n",
        "# model should be one of the following strings:\n",
        "# 'inception', 'resnet', 'mobilenet', 'efficientnet'\n",
        "\n",
        "class AttrModel:\n",
        "    def __init__(self, attribute, epochs, model, input_shape, batch_size, final_layer_neurons,\n",
        "                 X_train, X_test,\n",
        "                 y_train, y_test, **kwargs):\n",
        "        self.attribute = attribute\n",
        "        self.model = model.lower()\n",
        "        self.input_shape = input_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.final_layer_neurons = final_layer_neurons\n",
        "        self.kwargs = kwargs\n",
        "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.5\n",
        "        )\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.cat_nums = {\n",
        "            'design': 7,\n",
        "            'sleeves': 3,\n",
        "            'length': 2,\n",
        "            'neckline': 4,\n",
        "            'fabric': 6,\n",
        "            'fit': 3\n",
        "        }\n",
        "\n",
        "        del X_train\n",
        "        del y_train\n",
        "\n",
        "        self.cat_num = self.cat_nums[self.attribute]\n",
        "        self.activation = 'sigmoid' if self.attribute == 'length' else 'softmax'\n",
        "        self.loss = 'binary_crossentropy' if self.attribute == 'length' else 'categorical_crossentropy'\n",
        "        self.model = self.instantiate_model()  # calling the function below\n",
        "\n",
        "    def instantiate_model(self):\n",
        "        input = Input(self.input_shape)\n",
        "        #preprocess = Lambda(mobilenet.preprocess_input)\n",
        "\n",
        "        if self.model == 'inception':              # calling the chosen pretrained model\n",
        "            base_model = InceptionV3(include_top=False, weights='imagenet',\n",
        "                                    classes=self.cat_num, input_tensor=input)\n",
        "            self.preprocess_input = inception_v3.preprocess_input\n",
        "        elif self.model == 'resnet':\n",
        "            base_model = ResNet50(include_top=False, weights='imagenet',\n",
        "                                  classes=self.cat_num, input_tensore=input)\n",
        "            self.preprocess_input = resnet.preprocess_input\n",
        "        elif self.model == 'mobilenet':\n",
        "            base_model = MobileNetV2(include_top=False, weights='imagenet',\n",
        "                                     classes=self.cat_num, input_tensor=input)\n",
        "            self.preprocess_input = mobilenet.preprocess_input\n",
        "        elif self.model == 'efficientnet':\n",
        "            base_model = EfficientNetB0(include_top=False, weights='imagenet',\n",
        "                                        classes=self.cat_num, input_tensor=input)\n",
        "            self.preprocess_input = efficientnet.preprocess_input\n",
        "        else:\n",
        "            print('''No model found. Please pass one of the following:\n",
        "                  inception, resnet, mobilenet, efficientnet''')\n",
        "\n",
        "        base_model.trainable = False    # freeze layers\n",
        "        pool = GlobalAveragePooling2D()\n",
        "        dense = Dense(units=self.final_layer_neurons, activation='relu')\n",
        "        prediction = Dense(units=self.cat_num, activation=self.activation)\n",
        "        model = Sequential([base_model, pool, dense, prediction])\n",
        "        print(self.loss) # check loss func\n",
        "        model.compile(loss=self.loss, optimizer='adam',\n",
        "                      metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        datagen = ImageDataGenerator(preprocessing_function=self.preprocess_input)\n",
        "\n",
        "        self.train_generator = datagen.flow( \n",
        "        self.X_train, self.y_train,                                \n",
        "        batch_size=16)\n",
        "\n",
        "        self.val_generator = datagen.flow( \n",
        "        self.X_val, self.y_val,                                \n",
        "        batch_size=16)\n",
        "\n",
        "        self.test_generator = datagen.flow( \n",
        "        self.X_test, self.y_test,                                \n",
        "        batch_size=16)\n",
        "\n",
        "        # Train the model on the images and labels\n",
        "        self.model.history = self.model.fit(self.train_generator, \n",
        "        validation_data = self.val_generator,\n",
        "        epochs=self.epochs, batch_size=self.batch_size, verbose=1, \n",
        "        callbacks=[EarlyStopping(patience=2, restore_best_weights=True)])\n",
        "\n",
        "        return self.model.history\n",
        "\n",
        "    def finetune(self,callbacks=[EarlyStopping(patience=3)],\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy', Precision(), Recall()]):\n",
        "      \n",
        "        self.model.trainable = True     # unfreeze layers, then compile to save changes\n",
        "        self.model.compile(\n",
        "            optimizer=Adam(1e-5),                  # Very low learning rate\n",
        "            loss=loss,\n",
        "            metrics=metrics)\n",
        "        self.model.fit(self.val_generator,\n",
        "                       epochs=self.epochs, batch_size=self.batch_size,\n",
        "                       callbacks=[EarlyStopping(patience=2, monitor='val_accuracy', restore_best_weights=True)],\n",
        "                       validation_split=0.2)\n",
        "        return self.model.history\n",
        "\n",
        "    def evaluate(self):\n",
        "        return self.model.evaluate(self.test_generator, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n"
      ],
      "metadata": {
        "id": "RYPiOxL3vvLc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YAeTs3Tz49-u",
        "outputId": "acef8b15-c67d-4401-8da6-060e292e13f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorical_crossentropy\n"
          ]
        }
      ],
      "source": [
        "mobilnet = AttrModel(attribute='sleeves',\n",
        "                      model='mobilenet',\n",
        "                      input_shape=(224,224,3),\n",
        "                      batch_size= 16,\n",
        "                      epochs=50,\n",
        "                      final_layer_neurons=100,\n",
        "                      X_train=X_train,\n",
        "                      X_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilnet.train()"
      ],
      "metadata": {
        "id": "unQyCZR4igv_",
        "outputId": "cc3e28b3-c423-4a4e-c6d9-876ee9de53e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "810/810 [==============================] - 41s 37ms/step - loss: 0.4886 - accuracy: 0.8057 - precision_1: 0.8302 - recall_1: 0.7774 - val_loss: 0.3787 - val_accuracy: 0.8491 - val_precision_1: 0.8677 - val_recall_1: 0.8340\n",
            "Epoch 2/50\n",
            "810/810 [==============================] - 29s 36ms/step - loss: 0.3832 - accuracy: 0.8519 - precision_1: 0.8690 - recall_1: 0.8339 - val_loss: 0.3495 - val_accuracy: 0.8591 - val_precision_1: 0.8769 - val_recall_1: 0.8404\n",
            "Epoch 3/50\n",
            "810/810 [==============================] - 29s 35ms/step - loss: 0.3360 - accuracy: 0.8720 - precision_1: 0.8870 - recall_1: 0.8570 - val_loss: 0.2885 - val_accuracy: 0.8920 - val_precision_1: 0.9052 - val_recall_1: 0.8746\n",
            "Epoch 4/50\n",
            "810/810 [==============================] - 29s 35ms/step - loss: 0.2914 - accuracy: 0.8906 - precision_1: 0.9036 - recall_1: 0.8769 - val_loss: 0.2478 - val_accuracy: 0.9065 - val_precision_1: 0.9174 - val_recall_1: 0.8988\n",
            "Epoch 5/50\n",
            "810/810 [==============================] - 29s 35ms/step - loss: 0.2533 - accuracy: 0.9019 - precision_1: 0.9118 - recall_1: 0.8917 - val_loss: 0.1941 - val_accuracy: 0.9379 - val_precision_1: 0.9498 - val_recall_1: 0.9245\n",
            "Epoch 6/50\n",
            "810/810 [==============================] - 29s 36ms/step - loss: 0.2120 - accuracy: 0.9213 - precision_1: 0.9300 - recall_1: 0.9126 - val_loss: 0.1657 - val_accuracy: 0.9402 - val_precision_1: 0.9466 - val_recall_1: 0.9328\n",
            "Epoch 7/50\n",
            "810/810 [==============================] - 29s 36ms/step - loss: 0.1759 - accuracy: 0.9354 - precision_1: 0.9402 - recall_1: 0.9280 - val_loss: 0.1286 - val_accuracy: 0.9588 - val_precision_1: 0.9634 - val_recall_1: 0.9524\n",
            "Epoch 8/50\n",
            "810/810 [==============================] - 29s 35ms/step - loss: 0.1402 - accuracy: 0.9512 - precision_1: 0.9554 - recall_1: 0.9471 - val_loss: 0.1106 - val_accuracy: 0.9623 - val_precision_1: 0.9667 - val_recall_1: 0.9586\n",
            "Epoch 9/50\n",
            "242/810 [=======>......................] - ETA: 13s - loss: 0.0997 - accuracy: 0.9663 - precision_1: 0.9703 - recall_1: 0.9637"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-68f74c8d337d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-7f6474959d2f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Train the model on the images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         self.model.history = self.model.fit(self.train_generator, \n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilnet.save() # SAVE MODEL"
      ],
      "metadata": {
        "id": "9_xfF9c35hF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}