{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1G5hxCVmXqvCtUo2reGjaobM1j_JIdtHN",
      "authorship_tag": "ABX9TyMGA1dzVgp1QwX6ivemQ9xd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orlandoalexander/Moda-Personal-Assistant/blob/models/Matthias_category_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BuelJY1Wuqo8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from scipy import cluster\n",
        "import random\n",
        "import time\n",
        "from io import BytesIO\n",
        "from keras.layers import Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/orlandoalexander/Moda-Personal-Assistant.git@preproc_package"
      ],
      "metadata": {
        "id": "UcyRxZ1Cv85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1223e0a-6788-4005-ef79-1a92e084b8b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/orlandoalexander/Moda-Personal-Assistant.git@preproc_package\n",
            "  Cloning https://github.com/orlandoalexander/Moda-Personal-Assistant.git (to revision preproc_package) to /tmp/pip-req-build-ldt5v408\n",
            "  Running command git clone -q https://github.com/orlandoalexander/Moda-Personal-Assistant.git /tmp/pip-req-build-ldt5v408\n",
            "  Running command git checkout -b preproc_package --track origin/preproc_package\n",
            "  Switched to a new branch 'preproc_package'\n",
            "  Branch 'preproc_package' set up to track remote branch 'preproc_package' from 'origin'.\n",
            "Collecting pandas==1.4.4\n",
            "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.7 MB 3.8 MB/s \n",
            "\u001b[?25hCollecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 12 kB/s \n",
            "\u001b[?25hCollecting matplotlib==3.5.2\n",
            "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn-pandas==1.8.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.8.0)\n",
            "Requirement already satisfied: absl-py==1.3.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.8.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.6.3)\n",
            "Requirement already satisfied: cachetools==5.2.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (5.2.0)\n",
            "Requirement already satisfied: certifi==2022.9.24 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.1.1)\n",
            "Collecting flatbuffers==22.12.6\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.4.0)\n",
            "Requirement already satisfied: google-auth==2.15.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.4.6)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio==1.51.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.51.1)\n",
            "Collecting h5py==3.7.0\n",
            "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 28.1 MB/s \n",
            "\u001b[?25hCollecting idna==3.4\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 115 kB/s \n",
            "\u001b[?25hCollecting importlib-metadata==5.1.0\n",
            "  Downloading importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.1.2)\n",
            "Requirement already satisfied: libclang==14.0.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (14.0.6)\n",
            "Requirement already satisfied: Markdown==3.4.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.4.1)\n",
            "Collecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.2.2)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.3.0)\n",
            "Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (21.3)\n",
            "Requirement already satisfied: protobuf==3.19.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.19.6)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.2.8)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.6 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2022.6)\n",
            "Collecting requests==2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (4.9)\n",
            "Collecting scikit-learn==1.1.3\n",
            "  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tensorboard-data-server==0.6.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.8.1)\n",
            "Requirement already satisfied: termcolor==2.1.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (2.1.1)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions==4.4.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (4.4.0)\n",
            "Collecting urllib3==1.26.13\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 70.2 MB/s \n",
            "\u001b[?25hCollecting Werkzeug==2.2.2\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt==1.14.1 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (1.14.1)\n",
            "Requirement already satisfied: zipp==3.11.0 in /usr/local/lib/python3.8/dist-packages (from preproc==0.0.0) (3.11.0)\n",
            "Collecting keras==2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 89.4 MB/s \n",
            "\u001b[?25hCollecting tensorboard==2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 91.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 95.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse==1.6.3->preproc==0.0.0) (0.38.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 86.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->preproc==0.0.0) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->preproc==0.0.0) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->preproc==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11->preproc==0.0.0) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->preproc==0.0.0) (0.28.0)\n",
            "Building wheels for collected packages: preproc\n",
            "  Building wheel for preproc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preproc: filename=preproc-0.0.0-py3-none-any.whl size=12852477 sha256=da1f3ca8636ef1ac9aed1fc47cf6fbfc9ced768b9ec8faabf3411215713a1ce1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k8a53too/wheels/3a/d8/cf/a54e93734385125d287cb7e11625303456bc04eefd73764145\n",
            "Successfully built preproc\n",
            "Installing collected packages: urllib3, idna, six, requests, numpy, MarkupSafe, importlib-metadata, Werkzeug, scipy, tensorflow-estimator, tensorboard, scikit-learn, pandas, keras, h5py, fonttools, flatbuffers, tensorflow, matplotlib, preproc\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.13.0\n",
            "    Uninstalling importlib-metadata-4.13.0:\n",
            "      Successfully uninstalled importlib-metadata-4.13.0\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed MarkupSafe-2.1.1 Werkzeug-2.2.2 flatbuffers-22.12.6 fonttools-4.38.0 h5py-3.7.0 idna-3.4 importlib-metadata-5.1.0 keras-2.11.0 matplotlib-3.5.2 numpy-1.23.5 pandas-1.4.4 preproc-0.0.0 requests-2.28.1 scikit-learn-1.1.3 scipy-1.9.3 six-1.16.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 urllib3-1.26.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "h5py",
                  "keras",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "requests",
                  "six",
                  "sklearn",
                  "tensorboard",
                  "tensorflow",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QkGayRnBuua8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b139b4b4-e187-440f-96d0-1dfcd9646980"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip '/content/drive/MyDrive/Colab Notebooks/Data Moda/images.zip' "
      ],
      "metadata": {
        "id": "4ysq7SuHvrKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/images'"
      ],
      "metadata": {
        "id": "_byFLYM0vrQ_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from preproc.preprocess import AttributePreproc, SectionPreproc, CategoryPreproc"
      ],
      "metadata": {
        "id": "FyYt1f9Fviaz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep = CategoryPreproc(PATH, (224,224), 0.2)"
      ],
      "metadata": {
        "id": "n8bJ-ixJvifz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, names  = prep.run()"
      ],
      "metadata": {
        "id": "YTK-p5iuvije",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204a558a-4da6-4610-88a0-e1c236009476"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmenting category 'Tees'...\n",
            "Augmenting category 'Dresses'...\n",
            "Augmenting category 'Blouses'...\n",
            "Augmenting category 'Sweaters'...\n",
            "Augmenting category 'Rompers'...\n",
            "Augmenting category 'Shorts'...\n",
            "Augmenting category 'Pants'...\n",
            "Augmenting category 'Jackets'...\n",
            "Augmenting category 'Cardigans'...\n",
            "Augmenting category 'Skirts'...\n",
            "Augmenting category 'Joggers'...\n",
            "Augmenting category 'Graphic_Tees'...\n",
            "Augmenting category 'Shirts'...\n",
            "Augmenting category 'Baggy_Pants'...\n",
            "Augmenting category 'Suiting'...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model application"
      ],
      "metadata": {
        "id": "0WyoC7hcCif_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Orginal Class code\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Lambda, BatchNormalization, Dropout\n",
        "from keras import Sequential, Model\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "from keras.applications import InceptionV3\n",
        "from keras.applications import inception_v3\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications import MobileNetV3Large\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications import mobilenet_v2\n",
        "from keras.applications import EfficientNetB0\n",
        "from keras.applications import efficientnet\n",
        "from keras.applications import mobilenet\n",
        "from keras.applications import resnet\n",
        "from keras.applications import inception_v3\n",
        "from keras.models import save_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# attribute should be one of the following strings:\n",
        "# 'design', 'sleeves', 'length', 'neckline', 'fabric', 'fit'\n",
        "\n",
        "# model should be one of the following strings:\n",
        "# 'inception', 'resnet', 'mobilenet', 'efficientnet'\n",
        "\n",
        "class AttrModel(Model):\n",
        "    def __init__(self, attribute, epochs, model_name, in_shape, batch_size, callbacks, final_layer_neurons,\n",
        "                 pretrain_lr, finetune_lr,\n",
        "                 X_train, X_test,\n",
        "                 y_train, y_test, **kwargs):\n",
        "        super().__init__()\n",
        "        self.attribute = attribute\n",
        "        self.model_name = model_name.lower()\n",
        "        self.in_shape = in_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.pretrain_lr = pretrain_lr\n",
        "        self.finetune_lr = finetune_lr\n",
        "        self.callbacks = callbacks\n",
        "        self.final_layer_neurons = final_layer_neurons\n",
        "        self.kwargs = kwargs\n",
        "        self.X_pretrain, self.X_finetune, self.y_pretrain, self.y_finetune = train_test_split(\n",
        "            X_train, y_train, test_size=0.01, random_state = 2\n",
        "        )\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.cat_nums = {\n",
        "            'design': 7,\n",
        "            'sleeves': 3,\n",
        "            'length': 1,      # Binary category = 1\n",
        "            'neckline': 4,\n",
        "            'fabric': 6,\n",
        "            'fit': 3,\n",
        "            'category' : 15\n",
        "        }\n",
        "\n",
        "        del X_train\n",
        "        del y_train\n",
        "\n",
        "        self.cat_num = self.cat_nums[self.attribute]\n",
        "        self.activation ='softmax'\n",
        "        self.loss = 'categorical_crossentropy'\n",
        "        self.model = self.instantiate_model()  # calling the function below\n",
        "\n",
        "    def instantiate_model(self):\n",
        "        input = Input(self.in_shape)\n",
        "        #preprocess = Lambda(mobilenet.preprocess_input)\n",
        "\n",
        "        if self.model_name == 'inception':              # calling the chosen pretrained model\n",
        "            base_model = InceptionV3(include_top=False, weights='imagenet',\n",
        "                                    classes=self.cat_num, input_shape=self.in_shape)\n",
        "            self.preprocess_input = inception_v3.preprocess_input\n",
        "        elif self.model_name == 'resnet':\n",
        "            base_model = ResNet50(include_top=False, weights='imagenet',\n",
        "                                  classes=self.cat_num, input_shape=self.in_shape)\n",
        "            self.preprocess_input = resnet.preprocess_input\n",
        "        elif self.model_name == 'mobilenet':\n",
        "            base_model = MobileNetV2(include_top=False, weights='imagenet',\n",
        "                                     classes=self.cat_num, input_shape=self.in_shape)\n",
        "            self.preprocess_input = mobilenet.preprocess_input\n",
        "        elif self.model_name == 'efficientnet':\n",
        "            base_model = EfficientNetB0(include_top=False, weights='imagenet',\n",
        "                                        classes=self.cat_num, input_shape=self.in_shape)\n",
        "            self.preprocess_input = efficientnet.preprocess_input\n",
        "        else:\n",
        "            print('''No model found. Please pass one of the following:\n",
        "                  inception, resnet, mobilenet, efficientnet''')\n",
        "\n",
        "        base_model.trainable = False    # freeze layers\n",
        "        outputs = base_model(input)\n",
        "        outputs = BatchNormalization(name='BatchNormalization')(outputs)\n",
        "        outputs = GlobalAveragePooling2D()(outputs)\n",
        "        outputs = Dropout(0.5)(outputs)\n",
        "        outputs = Dense(units=self.final_layer_neurons, activation='relu')(outputs)\n",
        "        outputs = LeakyReLU(alpha=0.1)(outputs)\n",
        "        outputs = Dropout(0.25)(outputs)\n",
        "        outputs = Dense(units=self.cat_num, activation=self.activation)(outputs)\n",
        "        self.model = Model(inputs = [input], outputs = [outputs])\n",
        "        self.model.save('')\n",
        "        print(self.loss) # check loss func\n",
        "        self.model.compile(loss=self.loss, optimizer=Adam(learning_rate=self.pretrain_lr),\n",
        "                      metrics=['accuracy'])\n",
        "        return self.model\n",
        "\n",
        "    def train(self):\n",
        "            self.datagen = ImageDataGenerator(preprocessing_function=self.preprocess_input)\n",
        "            self.X_pretrain, self.X_val, self.y_pretrain, self.y_val = train_test_split(\n",
        "                self.X_pretrain, self.y_pretrain, test_size=0.2\n",
        "            )\n",
        "            self.pretrain_generator = self.datagen.flow(\n",
        "            self.X_pretrain, self.y_pretrain,\n",
        "            batch_size=16)\n",
        "            self.pretrain_val = self.datagen.flow(\n",
        "            self.X_val, self.y_val,\n",
        "            batch_size=16)\n",
        "            # Train the model on the images and labels\n",
        "            self.model.history = self.model.fit(self.pretrain_generator,validation_data = self.pretrain_val,\n",
        "            epochs=self.epochs, batch_size=self.batch_size, verbose=1,\n",
        "            callbacks=self.callbacks)\n",
        "            del self.pretrain_generator\n",
        "            del self.pretrain_val\n",
        "            return self.model.history\n",
        "\n",
        "    def finetune(self,\n",
        "                 metrics=['accuracy']):\n",
        "        self.datagen = ImageDataGenerator(preprocessing_function=self.preprocess_input)\n",
        "        self.X_finetune, self.X_fval, self.y_finetune, self.y_fval = train_test_split(\n",
        "                self.X_finetune, self.y_finetune, test_size=0.2)\n",
        "        self.finetune_generator = self.datagen.flow( \n",
        "        self.X_finetune, self.y_finetune,                                \n",
        "        batch_size=16)\n",
        "\n",
        "        self.X_fval = self.datagen.flow(\n",
        "        self.X_fval, self.y_fval,\n",
        "        batch_size=16)\n",
        "\n",
        "        self.model.trainable = True     # unfreeze layers, then compile to save changes\n",
        "        self.model.compile(\n",
        "            optimizer=Adam(self.finetune_lr),                  # Very low learning rate\n",
        "            loss=self.loss,\n",
        "            metrics=metrics)\n",
        "        self.model.fit(self.finetune_generator,\n",
        "                       epochs=self.epochs, batch_size=self.batch_size,\n",
        "                       callbacks=self.callbacks)\n",
        "        \n",
        "        del self.finetune_generator\n",
        "        return self.model, self.model.history\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.test_generator = self.datagen.flow( \n",
        "        self.X_test, self.y_test,                                \n",
        "        batch_size=16)\n",
        "        res = self.model.evaluate(self.test_generator, verbose=1)\n",
        "        del self.test_generator\n",
        "        return res\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(self.preprocess_input(X))\n",
        "\n",
        "\n",
        "    def save(self, filepath):\n",
        "        return save_model(self.model,\n",
        "                                   filepath=filepath)\n",
        "        \n",
        "    def summary(self):\n",
        "        return self.model.summary()\n"
      ],
      "metadata": {
        "id": "CCl9nZIMCocU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_category = AttrModel(attribute='category',\n",
        "                      model_name='mobilenet',\n",
        "                      in_shape=(224,224,3),\n",
        "                      batch_size= 16,\n",
        "                      epochs=100,\n",
        "                      pretrain_lr = .0001,\n",
        "                      finetune_lr = .00001,\n",
        "                      callbacks = EarlyStopping(patience=5, restore_best_weights=True),\n",
        "                      final_layer_neurons=100,\n",
        "                      X_train=X_train,\n",
        "                      X_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RLfiOd9CnSE",
        "outputId": "0c4e194f-2b1f-4339-8fb3-d4cc20827ced"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorical_crossentropy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_category.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_WgfqMHKnDF",
        "outputId": "06e21901-daa6-4887-effc-e71c36859f7a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "496/496 [==============================] - 25s 30ms/step - loss: 2.0471 - accuracy: 0.3530 - val_loss: 1.1988 - val_accuracy: 0.6507\n",
            "Epoch 2/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 1.2575 - accuracy: 0.5889 - val_loss: 0.8677 - val_accuracy: 0.7077\n",
            "Epoch 3/100\n",
            "496/496 [==============================] - 14s 29ms/step - loss: 1.0602 - accuracy: 0.6295 - val_loss: 0.7536 - val_accuracy: 0.7293\n",
            "Epoch 4/100\n",
            "496/496 [==============================] - 17s 34ms/step - loss: 0.9463 - accuracy: 0.6536 - val_loss: 0.6952 - val_accuracy: 0.7445\n",
            "Epoch 5/100\n",
            "496/496 [==============================] - 14s 29ms/step - loss: 0.8942 - accuracy: 0.6773 - val_loss: 0.6586 - val_accuracy: 0.7545\n",
            "Epoch 6/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.8219 - accuracy: 0.7030 - val_loss: 0.6333 - val_accuracy: 0.7646\n",
            "Epoch 7/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.7984 - accuracy: 0.7101 - val_loss: 0.6162 - val_accuracy: 0.7676\n",
            "Epoch 8/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.7748 - accuracy: 0.7188 - val_loss: 0.5963 - val_accuracy: 0.7812\n",
            "Epoch 9/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.7447 - accuracy: 0.7297 - val_loss: 0.5890 - val_accuracy: 0.7818\n",
            "Epoch 10/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.7259 - accuracy: 0.7395 - val_loss: 0.5742 - val_accuracy: 0.7928\n",
            "Epoch 11/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.7029 - accuracy: 0.7469 - val_loss: 0.5679 - val_accuracy: 0.7903\n",
            "Epoch 12/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.6862 - accuracy: 0.7498 - val_loss: 0.5572 - val_accuracy: 0.7918\n",
            "Epoch 13/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.6625 - accuracy: 0.7565 - val_loss: 0.5486 - val_accuracy: 0.7999\n",
            "Epoch 14/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.6568 - accuracy: 0.7609 - val_loss: 0.5426 - val_accuracy: 0.8034\n",
            "Epoch 15/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.6460 - accuracy: 0.7632 - val_loss: 0.5409 - val_accuracy: 0.7984\n",
            "Epoch 16/100\n",
            "496/496 [==============================] - 14s 29ms/step - loss: 0.6256 - accuracy: 0.7681 - val_loss: 0.5332 - val_accuracy: 0.8080\n",
            "Epoch 17/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.6189 - accuracy: 0.7740 - val_loss: 0.5237 - val_accuracy: 0.8059\n",
            "Epoch 18/100\n",
            "496/496 [==============================] - 14s 29ms/step - loss: 0.6088 - accuracy: 0.7743 - val_loss: 0.5242 - val_accuracy: 0.8049\n",
            "Epoch 19/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5910 - accuracy: 0.7824 - val_loss: 0.5212 - val_accuracy: 0.8024\n",
            "Epoch 20/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5876 - accuracy: 0.7836 - val_loss: 0.5169 - val_accuracy: 0.8039\n",
            "Epoch 21/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5779 - accuracy: 0.7836 - val_loss: 0.5118 - val_accuracy: 0.8085\n",
            "Epoch 22/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5524 - accuracy: 0.7970 - val_loss: 0.5076 - val_accuracy: 0.8110\n",
            "Epoch 23/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5689 - accuracy: 0.7940 - val_loss: 0.5076 - val_accuracy: 0.8125\n",
            "Epoch 24/100\n",
            "496/496 [==============================] - 14s 29ms/step - loss: 0.5600 - accuracy: 0.7965 - val_loss: 0.5016 - val_accuracy: 0.8125\n",
            "Epoch 25/100\n",
            "496/496 [==============================] - 15s 29ms/step - loss: 0.5309 - accuracy: 0.8015 - val_loss: 0.4985 - val_accuracy: 0.8170\n",
            "Epoch 26/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5246 - accuracy: 0.8066 - val_loss: 0.4958 - val_accuracy: 0.8165\n",
            "Epoch 27/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5335 - accuracy: 0.8059 - val_loss: 0.4969 - val_accuracy: 0.8211\n",
            "Epoch 28/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5201 - accuracy: 0.8084 - val_loss: 0.4952 - val_accuracy: 0.8175\n",
            "Epoch 29/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5311 - accuracy: 0.7986 - val_loss: 0.4950 - val_accuracy: 0.8145\n",
            "Epoch 30/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5263 - accuracy: 0.8057 - val_loss: 0.4904 - val_accuracy: 0.8201\n",
            "Epoch 31/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4958 - accuracy: 0.8122 - val_loss: 0.4871 - val_accuracy: 0.8201\n",
            "Epoch 32/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4980 - accuracy: 0.8184 - val_loss: 0.4882 - val_accuracy: 0.8191\n",
            "Epoch 33/100\n",
            "496/496 [==============================] - 14s 29ms/step - loss: 0.4987 - accuracy: 0.8185 - val_loss: 0.4833 - val_accuracy: 0.8175\n",
            "Epoch 34/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.5009 - accuracy: 0.8110 - val_loss: 0.4837 - val_accuracy: 0.8226\n",
            "Epoch 35/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4939 - accuracy: 0.8252 - val_loss: 0.4807 - val_accuracy: 0.8196\n",
            "Epoch 36/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4858 - accuracy: 0.8200 - val_loss: 0.4767 - val_accuracy: 0.8256\n",
            "Epoch 37/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4842 - accuracy: 0.8197 - val_loss: 0.4788 - val_accuracy: 0.8221\n",
            "Epoch 38/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4775 - accuracy: 0.8268 - val_loss: 0.4783 - val_accuracy: 0.8236\n",
            "Epoch 39/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4788 - accuracy: 0.8197 - val_loss: 0.4774 - val_accuracy: 0.8251\n",
            "Epoch 40/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4601 - accuracy: 0.8315 - val_loss: 0.4762 - val_accuracy: 0.8251\n",
            "Epoch 41/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4597 - accuracy: 0.8284 - val_loss: 0.4760 - val_accuracy: 0.8261\n",
            "Epoch 42/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4609 - accuracy: 0.8320 - val_loss: 0.4723 - val_accuracy: 0.8261\n",
            "Epoch 43/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4496 - accuracy: 0.8329 - val_loss: 0.4735 - val_accuracy: 0.8236\n",
            "Epoch 44/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4576 - accuracy: 0.8318 - val_loss: 0.4733 - val_accuracy: 0.8266\n",
            "Epoch 45/100\n",
            "496/496 [==============================] - 15s 30ms/step - loss: 0.4463 - accuracy: 0.8340 - val_loss: 0.4755 - val_accuracy: 0.8226\n",
            "Epoch 46/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4414 - accuracy: 0.8349 - val_loss: 0.4738 - val_accuracy: 0.8236\n",
            "Epoch 47/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4363 - accuracy: 0.8391 - val_loss: 0.4715 - val_accuracy: 0.8291\n",
            "Epoch 48/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4360 - accuracy: 0.8391 - val_loss: 0.4670 - val_accuracy: 0.8266\n",
            "Epoch 49/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4360 - accuracy: 0.8389 - val_loss: 0.4692 - val_accuracy: 0.8291\n",
            "Epoch 50/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4249 - accuracy: 0.8450 - val_loss: 0.4670 - val_accuracy: 0.8276\n",
            "Epoch 51/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4242 - accuracy: 0.8407 - val_loss: 0.4671 - val_accuracy: 0.8317\n",
            "Epoch 52/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4254 - accuracy: 0.8425 - val_loss: 0.4703 - val_accuracy: 0.8266\n",
            "Epoch 53/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4287 - accuracy: 0.8371 - val_loss: 0.4670 - val_accuracy: 0.8362\n",
            "Epoch 54/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4241 - accuracy: 0.8430 - val_loss: 0.4638 - val_accuracy: 0.8317\n",
            "Epoch 55/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4192 - accuracy: 0.8447 - val_loss: 0.4634 - val_accuracy: 0.8342\n",
            "Epoch 56/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4120 - accuracy: 0.8483 - val_loss: 0.4626 - val_accuracy: 0.8342\n",
            "Epoch 57/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4116 - accuracy: 0.8498 - val_loss: 0.4618 - val_accuracy: 0.8337\n",
            "Epoch 58/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4097 - accuracy: 0.8469 - val_loss: 0.4622 - val_accuracy: 0.8367\n",
            "Epoch 59/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4108 - accuracy: 0.8481 - val_loss: 0.4633 - val_accuracy: 0.8317\n",
            "Epoch 60/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4079 - accuracy: 0.8466 - val_loss: 0.4649 - val_accuracy: 0.8357\n",
            "Epoch 61/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4131 - accuracy: 0.8431 - val_loss: 0.4633 - val_accuracy: 0.8352\n",
            "Epoch 62/100\n",
            "496/496 [==============================] - 14s 28ms/step - loss: 0.4068 - accuracy: 0.8445 - val_loss: 0.4637 - val_accuracy: 0.8387\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a29660730>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=mobilenet_category.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmRPRqXEKT1l",
        "outputId": "64c630e1-bd3b-4954-8a9d-028342f65e59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 4s 24ms/step - loss: 0.4796 - accuracy: 0.8216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_category.save('/content/drive/MyDrive/Colab_Notebooks/model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZsQHIFpRCBh",
        "outputId": "e1c09b6e-c43a-401e-81cf-3cd586bad95f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_category.finetune()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "eOWrMdMaJRaV",
        "outputId": "a692a403-4da7-46e2-8196-f936e68245e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "151/151 [==============================] - ETA: 0s - loss: 2.8225 - accuracy: 0.0940"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 23s 70ms/step - loss: 2.8225 - accuracy: 0.0940\n",
            "Epoch 2/50\n",
            "151/151 [==============================] - ETA: 0s - loss: 2.5938 - accuracy: 0.1681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 10s 66ms/step - loss: 2.5938 - accuracy: 0.1681\n",
            "Epoch 3/50\n",
            "151/151 [==============================] - ETA: 0s - loss: 2.3210 - accuracy: 0.2683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 10s 68ms/step - loss: 2.3210 - accuracy: 0.2683\n",
            "Epoch 4/50\n",
            "151/151 [==============================] - ETA: 0s - loss: 2.1250 - accuracy: 0.3261"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 10s 68ms/step - loss: 2.1250 - accuracy: 0.3261\n",
            "Epoch 5/50\n",
            "151/151 [==============================] - ETA: 0s - loss: 1.9438 - accuracy: 0.3873"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151/151 [==============================] - 10s 68ms/step - loss: 1.9438 - accuracy: 0.3873\n",
            "Epoch 6/50\n",
            " 98/151 [==================>...........] - ETA: 3s - loss: 1.7868 - accuracy: 0.4503"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f20067eee35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmobilenet_category\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-4865db1e0939>\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(self, metrics)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             metrics=metrics)\n\u001b[0;32m--> 147\u001b[0;31m         self.model.fit(self.finetune_generator,\n\u001b[0m\u001b[1;32m    148\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                        callbacks=self.callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \"\"\"\n\u001b[1;32m   1154\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_category.evaluate()"
      ],
      "metadata": {
        "id": "bNgoYhJMNi5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model - VGG19 model"
      ],
      "metadata": {
        "id": "AmO28FAJoQ80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "def load_model():\n",
        "    \n",
        "    # $CHALLENGIFY_BEGIN\n",
        "    \n",
        "    model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "    \n",
        "    # $CHALLENGIFY_END\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "i744UYHkoUPR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knpa-jvpocLK",
        "outputId": "e8c7bce8-0a5d-4e47-a96a-7af99632e5a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_nontrainable_layers(model):\n",
        "    \n",
        "    # $CHALLENGIFY_BEGIN\n",
        "    # Set the first layers to be untrainable\n",
        "    model.trainable = False\n",
        "    \n",
        "    # $CHALLENGIFY_END\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "gQm7cxV8Ps5Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import dropout\n",
        "from keras import layers, models\n",
        "\n",
        "def add_last_layers(model):\n",
        "    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n",
        "    # $CHALLENGIFY_BEGIN\n",
        "    base_model = set_nontrainable_layers(model)\n",
        "    flatten_layer = layers.Flatten()\n",
        "    dense_layer = layers.Dense(1024, activation='relu')\n",
        "    dropout_layer = layers.Dropout(0.5)\n",
        "    dense_layer2 = layers.Dense(1024, activation='relu')\n",
        "    prediction_layer = layers.Dense(15, activation='softmax')\n",
        "    \n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        flatten_layer,\n",
        "        dense_layer,\n",
        "        dropout_layer,\n",
        "        dense_layer2,\n",
        "        prediction_layer\n",
        "    ])\n",
        "    # $CHALLENGIFY_END\n",
        "    return model"
      ],
      "metadata": {
        "id": "HR5TOU0oocSh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = add_last_layers(model)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrfMxO9focWq",
        "outputId": "15343a2d-f53d-4dff-b52a-4e993e0d2c7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 15)                15375     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,780,495\n",
            "Trainable params: 26,756,111\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "def build_model():\n",
        "    # $CHALLENGIFY_BEGIN    \n",
        "    model = load_model()\n",
        "    model = add_last_layers(model)\n",
        "    \n",
        "    opt = optimizers.Adam()\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "                  #metrics=[Precision(), Recall()])\n",
        "    return model\n",
        "    # $CHALLENGIFY_END"
      ],
      "metadata": {
        "id": "e_vhRiAbocaL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOkt8QcgocdO",
        "outputId": "8ab02f26-2459-4601-b258-42ea65dcb360"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 15)                15375     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,780,495\n",
            "Trainable params: 26,756,111\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/256"
      ],
      "metadata": {
        "id": "eOMgl-9FQNQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "model = build_model()\n",
        "\n",
        "es = EarlyStopping(monitor = 'val_accuracy', \n",
        "                   patience = 5, \n",
        "                   verbose = 1, \n",
        "                   restore_best_weights = True)\n",
        "\n",
        "history1 = model.fit(X_train, y_train,\n",
        "               epochs=10, \n",
        "               batch_size = 32,\n",
        "               callbacks=[es], \n",
        "               validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "0jmFWM8nocgy",
        "outputId": "bc10d945-3976-46ca-8a66-76db15c47309"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "242/242 [==============================] - 65s 252ms/step - loss: 7.0790 - accuracy: 0.4690 - val_loss: 24.2604 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            " 19/242 [=>............................] - ETA: 41s - loss: 2.4437 - accuracy: 0.4507"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2ed01d9eb268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    restore_best_weights = True)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m history1 = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     11\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HDqFpx3ock4",
        "outputId": "16e7c7dc-c8f1-4441-89dc-9d458d33f3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 15s 202ms/step - loss: 2.3621 - accuracy: 0.2410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.362133264541626, 0.24097885191440582]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('test_model.tf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-24JD-Nobdz",
        "outputId": "7293dabe-be30-4e51-dc17-f46846c86bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7efde937a4c0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7efde937a4c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7efde937a4c0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7efde937a4c0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "piocsuFt-nWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}